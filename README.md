# ğŸ›°ï¸ BiTemporal-StreetView-Damage

Hyperlocal disaster damage assessment using bi-temporal street-view imagery and pre-trained vision models.

<p align="center">
  <img src="images/study_area_disaster_damage_made.png" alt="Study Area" width="600"/>
</p>

---

## ğŸ“Œ Introduction

This project aims to enhance disaster damage perception and localization through **bi-temporal street-view imagery** (before and after disaster events). We leverage **pre-trained vision and vision-language models** (e.g., Swin Transformer and ConvNeXt, GPT-4o) to analyze fine-grained street-level damage in a hyperlocal context.

Key contributions include:
ï¼ˆ1ï¼‰Dual-channel model for damage assessment using bi-temporal street-view images.
ï¼ˆ2ï¼‰The dataset includes 2,249 labeled pre/post-disaster street-view image pairs.
ï¼ˆ3ï¼‰Outperforms baseline: Our model improves accuracy from 66.14% to 77.11%.
ï¼ˆ4ï¼‰Grad-CAM confirms the benefits of adding pre-disaster context for model focus.
ï¼ˆ5ï¼‰Enables rapid hyperlocal damage assessment for resilient city planning.


---

## ğŸ§  Paper Reference

> Yang, Y., Zou, L., Zhou, B., Li, D., Lin, B., Abedin, J., & Yang, M. (2025).  
> *Hyperlocal disaster damage assessment using bi-temporal street-view imagery and pre-trained vision models*.  
> arXiv preprint [arXiv:2504.09066](https://arxiv.org/abs/2504.09066)

---

## ğŸ“ Repository Structure

```bash
BiTemporal-StreetView-Damage/
â”‚
â”œâ”€â”€ codes/                          # Source code for model implementation and experiments
â”œâ”€â”€ images/                         # Figures and illustrations
â”‚   â”œâ”€â”€ study_area_disaster_damage_made.png
â”‚   â”œâ”€â”€ architect1.drawio_1.png
â”‚   â”œâ”€â”€ design_experiment.drawio_1.png
â”‚   â”œâ”€â”€ dual_channel.drawio_2.png
â”‚   â”œâ”€â”€ 0204-06.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

