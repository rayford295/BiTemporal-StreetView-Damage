{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3557f3a2",
      "metadata": {
        "id": "3557f3a2"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import shutil\n",
        "import base64\n",
        "import csv\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ef433c",
      "metadata": {
        "id": "a7ef433c"
      },
      "outputs": [],
      "source": [
        "api_key = \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ee2a6f",
      "metadata": {
        "id": "19ee2a6f"
      },
      "outputs": [],
      "source": [
        "def prepare_example_prompt(example_image_path, example_summary):\n",
        "    # Load the example image\n",
        "    with open(example_image_path, \"rb\") as img_file:\n",
        "        example_image = img_file.read()\n",
        "\n",
        "    # Format the prompt with the example image and summary\n",
        "    example_prompt = (\n",
        "        \"Here is an example of an image and its summary:\\n\\n\"\n",
        "        \"Image: [Example image provided below]\\n\"\n",
        "        f\"Summary: {example_summary}\\n\\n\"\n",
        "        \"Now, analyze this new image in the same format:\\n\"\n",
        "        \"Image: [New image provided below]\\n\"\n",
        "        \"Summary:\"\n",
        "    )\n",
        "\n",
        "    return example_prompt, example_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7215d972",
      "metadata": {
        "id": "7215d972"
      },
      "outputs": [],
      "source": [
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "def generate_summary_for_image(image_path, prompt):\n",
        "    base64_image = encode_image(image_path)\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides building condition annotations.\"},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt}\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
        "            ]}\n",
        "        ],\n",
        "#         max_tokens=300,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c58149cb",
      "metadata": {
        "id": "c58149cb"
      },
      "outputs": [],
      "source": [
        "def generate_contrast_for_image(image_path_before, image_path_after, prompt):\n",
        "    base64_image_before = encode_image(image_path_before)\n",
        "    base64_image_after = encode_image(image_path_after)\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides hurricane condition annotations.\"},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image_before}\"}},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image_after}\"}},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt}\"},\n",
        "            ]}\n",
        "        ],\n",
        "#         max_tokens=300,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b2d1ae",
      "metadata": {
        "id": "95b2d1ae"
      },
      "outputs": [],
      "source": [
        "def classify_image(image_path_before, image_path_after, prompt, prompt_summary, prompt_contrast):\n",
        "    base64_image_before = encode_image(image_path_before)\n",
        "    base64_image_after = encode_image(image_path_after)\n",
        "\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides hurricane condition annotations.\"},\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image_before}\"}},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image_after}\"}},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt_summary[0]}\"},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt_summary[1]}\"},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt_summary[2]}\"},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt_summary[3]}\"},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt_contrast}\"},\n",
        "                {\"type\": \"text\", \"text\": f\"{prompt}\"},\n",
        "            ]}\n",
        "        ],\n",
        "#         max_tokens=300,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a8e8fd",
      "metadata": {
        "id": "e6a8e8fd"
      },
      "outputs": [],
      "source": [
        "def process_response(response):\n",
        "    lines = response.strip().split(\"\\n\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for line in lines:\n",
        "        if 'score:' in line:\n",
        "            description, score = line.split('score:')\n",
        "            description = description.strip()\n",
        "            score_value = int(score.split('/')[0].strip())\n",
        "            results[description] = score_value\n",
        "\n",
        "        elif 'degree:' in line:\n",
        "            description, degree = line.split('degree:')\n",
        "            description = description.strip()\n",
        "            degree_value = degree.strip()\n",
        "\n",
        "            if degree_value == 'minor damage':\n",
        "                degree_value = \"Minor\"\n",
        "            elif degree_value == 'moderate damage':\n",
        "                degree_value = \"Moderate\"\n",
        "            elif degree_value == 'severe damage':\n",
        "                degree_value = \"Severe\"\n",
        "\n",
        "            results[description] = degree_value\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca5c5ea",
      "metadata": {
        "id": "8ca5c5ea",
        "outputId": "6c30d406-444f-4c20-e677-0d3b58a0cb34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Folders: 2it [00:26, 13.02s/it]\n",
            "Processing Folders: 2it [00:18,  9.27s/it]\n",
            "Processing Folders: 2it [00:25, 12.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file created at ./final_pair_label_classified_folders/folder_2/image_summaries.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "#     base_dir = './datasets/matched_image_pairs_base'\n",
        "#     annotated_dir = './annotated_datasets/'\n",
        "#     csv_file_path = './image_summaries.csv'\n",
        "    base_dirs = ['./final_pair_label_classified_folders/folder_0/',\n",
        "                './final_pair_label_classified_folders/folder_1/',\n",
        "                './final_pair_label_classified_folders/folder_2/']\n",
        "    csv_file_name = 'image_summaries.csv'\n",
        "\n",
        "    for base_dir in base_dirs:\n",
        "        csv_file_path = base_dir + csv_file_name\n",
        "        with open(csv_file_path, mode='w', newline='') as csv_file:\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow([\"degree\",\"score\",\"trees\",\"trash\",\"building\",\"water\",\"image_path\",\"year\",\"root\",\"summary\",\"contrast\"])\n",
        "\n",
        "\n",
        "            # Traverse each subfolder and collect image paths\n",
        "    #         for root, _, files in os.walk(base_dir):\n",
        "            for root, _, files in tqdm(os.walk(base_dir), desc=\"Processing Folders\"):\n",
        "                files = [file for file in files if file.endswith('.png')]\n",
        "\n",
        "                for i in range(0, len(files), 2):\n",
        "                    if i + 1 < len(files):  # Ensure there are pairs of images\n",
        "                        file_1, file_2 = files[i], files[i + 1]\n",
        "\n",
        "                        image_path_1 = os.path.join(root, file_1)\n",
        "                        image_path_2 = os.path.join(root, file_2)\n",
        "\n",
        "                        year_1 = image_path_1[-8:-4] if image_path_1[-4:].lower() == '.png' else image_path_1[-4:]\n",
        "                        year_2 = image_path_2[-8:-4] if image_path_2[-4:].lower() == '.png' else image_path_2[-4:]\n",
        "\n",
        "                        if year_1.isdigit() and year_2.isdigit():\n",
        "                            if year_1 == \"2023\":\n",
        "                                file_before = file_1\n",
        "                                file_after = file_2\n",
        "                                year_before = year_1\n",
        "                                year_after = year_2\n",
        "                                image_path_before = image_path_1\n",
        "                                image_path_after = image_path_2\n",
        "                            elif year_1 == \"2024\":\n",
        "                                file_before = file_2\n",
        "                                file_after = file_1\n",
        "                                year_before = year_2\n",
        "                                year_after = year_1\n",
        "                                image_path_before = image_path_2\n",
        "                                image_path_after = image_path_1\n",
        "\n",
        "                        prompts = [\n",
        "                            \"Based on fallen trees, describe the damage situation in 50 words.\",\n",
        "                            \"Based on housing trash, describe the damage situation in 50 words.\",\n",
        "                            \"Based on street signs or destroyed buildings, describe the damage situation in 50 words.\",\n",
        "                            \"Based on standing water in the street, describe the damage situation in 50 words.\",\n",
        "                            \"The first image is a photo before the disaster, and the second is a photo after the disaster, depicting the disaster and the changes after the disaster according to the content of the picture in 50 words.\"\n",
        "                        ]\n",
        "\n",
        "                        summary_after = []\n",
        "                        summary_tree = generate_summary_for_image(image_path_after, prompts[0])\n",
        "                        summary_trash = generate_summary_for_image(image_path_after, prompts[1])\n",
        "                        summary_building = generate_summary_for_image(image_path_after, prompts[2])\n",
        "                        summary_water = generate_summary_for_image(image_path_after, prompts[3])\n",
        "                        summary_after.append(summary_tree)\n",
        "                        summary_after.append(summary_trash)\n",
        "                        summary_after.append(summary_building)\n",
        "                        summary_after.append(summary_water)\n",
        "    #                     print(f\"Summary: {summary_after}\")\n",
        "\n",
        "                        summary_contrast = generate_contrast_for_image(image_path_before, image_path_after, prompts[-1])\n",
        "    #                     print(f\"Summary: {summary_contrast}\")\n",
        "\n",
        "                        prompt = \"The first picture is a photo before the disaster, and the second picture is after the disaster, \\\n",
        "                        and according to the content and text in the picture, \\\n",
        "                        the disasters that caused these changes are divided into three categories: minordamage, moderate damage, and severedamage. \\\n",
        "                        light damage images are characterized by a clean scene with no significant damage or only light damage, such as small areas of fallen trees or a few small road signs knocked down. \\\n",
        "                        Medium damage images are relatively cluttered and typically include larger or more extensive areas of fallen trees, as well as standing water around the trees. \\\n",
        "                        These images may also show more fallen road signs or road closure signs. \\\n",
        "                        Heavy damage images are very chaotic, featuring large or extensive areas of fallen trees, flooded roads, and housing trash. \\\n",
        "                        The output is one of these three categories for the second image. \\\n",
        "                        I dont need any explanation. \\\n",
        "                        The output format is as follows: \\\n",
        "                        fallen trees score: [fallen trees score / 100] \\\n",
        "                        housing trash score: [housing trash score / 100] \\\n",
        "                        destroy buildings score: [destroy buildings score / 100] \\\n",
        "                        standing water in the street score: [standing water in the street score / 100] \\\n",
        "                        damage degree score: [damage degree score / 100] \\\n",
        "                        damage degree: [minor damage, moderate damage, and severe damage]\"\n",
        "                        response = classify_image(image_path_before, image_path_after, prompt, summary_after, summary_contrast)\n",
        "                        score = process_response(response)\n",
        "\n",
        "                        normalized_root = root.replace('\\\\', '/')\n",
        "                        writer.writerow([score['damage'], score['damage degree'], score['fallen trees'], score['housing trash'], score['destroy buildings'], score['standing water in the street'], file_after[:-4], year_after, normalized_root, summary_after, summary_contrast])\n",
        "    #                     relative_path = os.path.relpath(image_path, base_dir)\n",
        "    #                     target_path = os.path.join(annotated_dir, relative_path)\n",
        "    #                     os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "\n",
        "                        # shutil.copy(image_path, target_path)\n",
        "\n",
        "    print(f\"CSV file created at {csv_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6eac71d",
      "metadata": {
        "id": "d6eac71d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:probing]",
      "language": "python",
      "name": "conda-env-probing-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}